# Chunking 방법론

## 목차
1. [Chunking 방법론 소개](#chunking-방법론-소개)
2. [15가지 Chunking 전략](#15가지-chunking-전략)
3. [핵심 내용](#핵심-내용)

## Chunking 방법론 소개

RAG(Retrieval-Augmented Generation) 시스템에서 데이터를 어떻게 분할(Chunk)하느냐에 따라 검색 성능과 정확도가 크게 달라짐. 문서의 형태와 질문 패턴에 맞는 적절한 청킹 전략을 선택하는 것이 중요함.

## 15가지 Chunking 전략

### 1. Line-by-Line Chunking
> 새 줄이 나올 때마다 분리

**📌 적용 시점**
- 채팅 로그, 대화 기록, 각 줄이 하나의 생각을 담고 있는 데이터
- **적합한 사례**: 고객 지원 채팅, 인터뷰 Q&A, 메신저 로그

**📌 이유**
- 각 메시지가 독립된 컨텍스트를 가짐
- 매우 세밀한 검색에 좋음 → LLM이 정확한 Q&A 페어를 가져오기 쉬움
- ⚠️ **주의**: 각 줄이 너무 짧으면 문맥 부족이 발생할 수 있음


### 2. Fixed-Size Chunking
> 의미와 상관없이 단어 수/문자 수를 기준으로 일정한 크기로 분리

**📌 적용 시점**
- 자연스러운 경계가 전혀 없는 지저분한 텍스트
- **적합한 사례**: OCR 결과 덤프, 웹 크롤링한 원시 텍스트, 오래된 스캔 문서

**📌 이유**
- 모든 청크 크기가 일정해짐
- 문장/아이디어가 중간에 잘릴 수 있어 이해력 저하
- 구조가 전혀 없을 때만 사용, LLM 토큰 한도를 고려해 청크 크기를 조절

### ⭐️ 3. Sliding Window Chunking
> 청크 사이에 일정 수의 단어/토큰을 겹치게(Overlap) 해서 분리

**📌 적용 시점**
- 아이디어/문장이 청크 경계를 넘나드는 경우
- **적합한 사례**: 서술형 텍스트, 법률 문서, 기술 문서

**📌 이유**
- 청크 경계에서 문맥이 끊기지 않도록 연속성을 유지
- 청크들 사이에 중복(중복 토큰)이 발생하지만, 문맥 보존에 탁월

### 4. Sentence-Based Chunking
> 각 문장을 하나의 청크로 설정

**📌 적용 시점**
- 문법이 잘 정리된 깔끔한 텍스트
- **적합한 사례**: 기사, 문서, 교재

**📌 이유**
- 각 청크가 하나의 집중된 아이디어를 담음
- LLM이 문맥을 재구성하기 쉬움
- ⚠️ **단점**: 어떤 문장은 너무 짧아서 문맥이 부족할 수 있음
- 💡 **팁**: 2~3문장을 묶어서 하나의 청크로 만드는 경우도 존재

### ⭐️ 5. Paragraph Chunking
> 각 문단을 하나의 청크로 사용

**📌 적용 시점**
- 잘 정리된 문서, 블로그 글, 에세이 등
- 일반적으로 문단 하나가 하나의 아이디어/토픽을 가짐

**📌 이유**
- 논리적인 흐름과 문맥이 잘 보존됨
- 좀 더 큰 "생각 단위(thought block)"를 통째로 검색하기 좋음

### ⭐️ 6. Page-Based Chunking
> 페이지가 있는 문서에서 각 페이지를 하나의 청크로 구성

**📌 적용 시점**
- PDF, 책, 스캔 문서, 계약서 등
- 페이지 번호 기준으로 참조해야 할 때 필수

**📌 이유**
- 페이지 구조가 중요할 때(법적 증거, 계약서, 교재 등) 필수적인 전략

### ⭐️ 7. Section or Heading-Based Chunking
> 제목/섹션(H1/H2, "## 섹션 제목" 등)을 기준으로 분리

**📌 적용 시점**
- 논리적인 섹션이 분명한 문서
- **적합한 사례**: 기술 문서, 책, 백서(whitepaper) 등

**📌 이유**
- 자연스러운 토픽 경계와 청크가 일치 → 검색 정확도 향상
- 검색 시 한 섹션 전체(하나의 주제)를 통째로 가져올 수 있음

### 8. Keyword-Based Chunking
> 특정 키워드(Ex. "Step", "Diagnosis", "Note")가 등장할 때마다 잘라서 청크 생성

**📌 적용 시점**
- 반복되는 키워드가 구조를 나타내는 문서
- **예시**: 의료 기록, 단계별 가이드, 로그

**📌 이유**
- 관련된 정보를 한 덩어리로 유지할 수 있음
- 구조화된 기록에 매우 적합

### 9. Entity-Based Chunking
> NER(개체명 인식)을 사용해 사람, 조직, 제품 등의 엔티티별로 문장/문단을 묶음

**📌 적용 시점**
- 뉴스, 법률 문서, 상품 리뷰처럼 누가/어디가 중요한 문서

**📌 이유**
- 엔티티 중심 검색이 가능해짐

### ⭐️ 10. Token-Based Chunking
> 단어 수가 아니라 토큰 수(LLM이 실제로 처리하는 단위)를 기준으로 나눔

**📌 적용 시점**
- LLM의 컨텍스트 크기 제한(예: 1024, 2048 토큰 등)을 정확히 맞추고 싶을 때

**📌 이유**
- 모델 입력 크기를 정교하게 제어할 수 있어, 잘리는 문제를 방지
- API 기반 앱에서 특히 유용

### ⭐️ 11. Table Chunking
> 각 테이블을 별도의 청크로 추출

**📌 적용 시점**
- 청구서, 재무 보고서, 논문 등의 표가 중요한 문서

**📌 이유**
- 테이블을 구조화된 데이터로 다루기 쉬움
- 테이블 청크만 가져와서 답변 가능

### 12. Recursive Chunking
> 먼저 크게 나누고(문단/섹션 단위), 크기가 너무 큰 청크를 다시 문장 → 단어 순으로 세분화해서 원하는 크기에 맞출 때까지 반복

**📌 적용 시점**
- 문단 길이가 들쭉날쭉한 긴 인터뷰, 회의록, 문서

**📌 이유**
- 어떤 청크도 시스템이 처리할 수 있는 크기를 넘지 않도록 보장

### ⭐️ 13. Semantic Chunking
> 임베딩/AI를 활용해 서로 같은 주제를 다루는 문장/문단을 자동으로 그룹핑

**📌 적용 시점**
- 다양한 주제가 섞여 있는 데이터
- **예시**: 고객지원 티켓, Q&A 문서, FAQ 등

**📌 이유**
- 사용자의 의도와 관련된 답변을 한 번에 모아서 가져오기 좋음
- 문맥 부족/헛소리를 줄이는 데 큰 도움

### 14. Hierarchical Chunking
> 여러 레벨의 구조를 활용해 챕터 → 섹션 → 문단 순으로 단계적으로 나누는 방식

**📌 적용 시점**
- 큰 규모의 구조화된 텍스트
- **예시**: 책, 기술 문서, 법령집 등

**📌 이유**
- RAG 시스템이 넓은 정보(챕터 단위)와 세부 정보(섹션 단위)를 계층적으로 검색할 수 있음

### ⭐️ 15. Content-Type Aware Chunking
> 텍스트/표/리스트/이미지 등 컨텐츠 타입별로 서로 다른 청킹 전략을 적용

**📌 적용 시점**
- 여러 타입의 콘텐츠가 섞여 있는 문서
- **예시**: PDF, 논문, 리포트 등

**📌 이유**
- 테이블/텍스트/이미지를 섞어버리지 않고 타입별로 분리해서 검색

## 핵심 내용

### 💡 주요 인사이트

1. **검색이 곧 성능**
   - RAG 성능은 "무엇을 검색해 올 것인가"에 달려 있고, 이것은 결국 데이터를 어떻게 쪼개서 인덱싱했는지에 의해 결정됨

2. **문서 형태에 맞는 전략 선택**
   - 청킹 전략은 문서의 형태(채팅, PDF, 논문, 로그, 표 등)와 질문 패턴(페이지 기반 질의, 엔티티 기반 질의, 개념/의미 기반 질의 등)에 맞게 골라야 함

3. **하이브리드 접근**
   - 단일 전략만 쓰지 말고, 필요에 따라 여러 전략을 조합하거나 계층적・재귀적으로 사용하는 것이 중요함

### 🎯 실전 가이드

| 문서 타입 | 추천 전략 |
|---------|---------|
| 채팅/대화 로그 | Line-by-Line Chunking |
| 기술 문서 | Section-Based + Sliding Window |
| PDF/계약서 | Page-Based + Table Chunking |
| FAQ/Q&A | Semantic Chunking |
| 논문/리포트 | Content-Type Aware + Hierarchical |
| 긴 인터뷰/회의록 | Recursive Chunking |

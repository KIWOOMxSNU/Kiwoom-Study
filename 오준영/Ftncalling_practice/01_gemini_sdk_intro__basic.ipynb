{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini SDK ê¸°ë³¸ ì´í•´\n",
    "\n",
    "**í•™ìŠµ ëª©í‘œ**\n",
    "- `google-genai` SDK êµ¬ì¡° íŒŒì•…\n",
    "- `types` ëª¨ë“ˆì˜ ì—­í• ê³¼ ì£¼ìš” í´ë˜ìŠ¤ ì´í•´\n",
    "- Client, GenerateContentConfig ë“± í•µì‹¬ ê°ì²´ ì´í•´\n",
    "\n",
    "**ì°¸ê³  ìë£Œ**\n",
    "- [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)\n",
    "- [SDK API ë¬¸ì„œ](https://googleapis.github.io/python-genai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)\n",
    "# !uv pip install google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ import\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ: {api_key[:10]}...\")\n",
    "else:\n",
    "    print(\"âŒ GEMINI_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Client ê°ì²´\n",
    "\n",
    "### `genai.Client()` - SDKì˜ ì§„ì…ì \n",
    "\n",
    "ëª¨ë“  Gemini API í˜¸ì¶œì˜ ì‹œì‘ì ì…ë‹ˆë‹¤. `requests.Session()`ì´ë‚˜ DB ì»¤ë„¥ì…˜ê³¼ ìœ ì‚¬í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**íŒŒë¼ë¯¸í„°:**\n",
    "- `api_key` (str, ì„ íƒ): Gemini API í‚¤. í™˜ê²½ë³€ìˆ˜ `GEMINI_API_KEY`ë¡œë„ ìë™ ì¸ì‹\n",
    "\n",
    "**ë°˜í™˜:** `Client` ê°ì²´\n",
    "\n",
    "**ì˜ˆì‹œ:** `client = genai.Client(api_key=\"your-key\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client ìƒì„±\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "print(f\"âœ… Client ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"ğŸ“¦ Client íƒ€ì…: {type(client)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `client.models.generate_content()` - í…ìŠ¤íŠ¸ ìƒì„±\n",
    "\n",
    "ê°€ì¥ ê¸°ë³¸ì ì¸ API í˜¸ì¶œ ë©”ì„œë“œì…ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**íŒŒë¼ë¯¸í„°:**\n",
    "- `model` (str, í•„ìˆ˜): ì‚¬ìš©í•  ëª¨ë¸ëª… (ì˜ˆ: `\"gemini-2.5-flash\"`)\n",
    "- `contents` (str | list, í•„ìˆ˜): í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ë˜ëŠ” Content ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "- `config` (GenerateContentConfig, ì„ íƒ): ìƒì„± ì„¤ì • (ì˜¨ë„, í† í° ìˆ˜ ë“±)\n",
    "\n",
    "**ë°˜í™˜:** `GenerateContentResponse` ê°ì²´\n",
    "\n",
    "**ì˜ˆì‹œ:** `response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=\"ì•ˆë…•?\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Pythonì˜ ì¥ì ì„ 3ê°€ì§€ë§Œ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ ì‘ë‹µ:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response ê°ì²´ êµ¬ì¡° íƒìƒ‰\n",
    "print(\"ğŸ” response ê°ì²´ì˜ ì£¼ìš” ì†ì„±ë“¤:\")\n",
    "print(f\"  - type: {type(response)}\")\n",
    "print(f\"  - text: {response.text[:50]}...\")\n",
    "print(f\"  - candidates ê°œìˆ˜: {len(response.candidates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. types ëª¨ë“ˆ í•´ë¶€\n",
    "\n",
    "`google.genai.types`ëŠ” SDKì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ë°ì´í„° êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.  \n",
    "JavaScriptì˜ TypeScript íƒ€ì… ì •ì˜, Pythonì˜ Pydantic ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì—­í• ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `types.Content` - ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ\n",
    "\n",
    "í•˜ë‚˜ì˜ ëŒ€í™” í„´(turn)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. OpenAIì˜ `{\"role\": \"user\", \"content\": \"...\"}`ì™€ ë™ì¼í•œ ê°œë…ì…ë‹ˆë‹¤.\n",
    "\n",
    "**íŒŒë¼ë¯¸í„°:**\n",
    "- `role` (str, í•„ìˆ˜): `\"user\"` ë˜ëŠ” `\"model\"`\n",
    "- `parts` (list[Part], í•„ìˆ˜): ë©”ì‹œì§€ ë‚´ìš© ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "**ì˜ˆì‹œ:** `types.Content(role=\"user\", parts=[types.Part(text=\"ì•ˆë…•\")])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content ê°ì²´ ìƒì„±\n",
    "user_message = types.Content(\n",
    "    role=\"user\",\n",
    "    parts=[types.Part(text=\"ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\")]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¦ Content êµ¬ì¡°:\")\n",
    "print(f\"  - role: {user_message.role}\")\n",
    "print(f\"  - parts: {user_message.parts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `types.Part` - ë©”ì‹œì§€ ì¡°ê°\n",
    "\n",
    "í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì½˜í…ì¸ ë¥¼ ë‹´ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ì†ì„±:**\n",
    "- `text` (str): í…ìŠ¤íŠ¸ ë‚´ìš©\n",
    "- `function_call` (FunctionCall): í•¨ìˆ˜ í˜¸ì¶œ ì •ë³´\n",
    "- `function_response` (FunctionResponse): í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "\n",
    "**ì˜ˆì‹œ:** `types.Part(text=\"ì•ˆë…•í•˜ì„¸ìš”\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part ê°ì²´ ìƒì„±\n",
    "text_part = types.Part(text=\"í•¨ìˆ˜ í˜¸ì¶œì„ ë°°ì›Œë´…ì‹œë‹¤\")\n",
    "\n",
    "print(f\"ğŸ“¦ Part êµ¬ì¡°:\")\n",
    "print(f\"  - text: {text_part.text}\")\n",
    "print(f\"  - function_call: {text_part.function_call}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `types.GenerateContentConfig` - ìƒì„± ì„¤ì •\n",
    "\n",
    "ëª¨ë¸ì˜ ë™ì‘ì„ ì œì–´í•˜ëŠ” ì„¤ì • ê°ì²´ì…ë‹ˆë‹¤. ì˜¨ë„, ìµœëŒ€ í† í°, ë„êµ¬ ë“±ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” íŒŒë¼ë¯¸í„°:**\n",
    "- `temperature` (float, 0~2): ì°½ì˜ì„± ì¡°ì ˆ. 0=ê²°ì •ì , 1=ê¸°ë³¸, 2=ì°½ì˜ì \n",
    "- `max_output_tokens` (int): ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜\n",
    "- `tools` (list): Function Callingì— ì‚¬ìš©í•  í•¨ìˆ˜ ëª©ë¡\n",
    "- `system_instruction` (str): ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "**ì˜ˆì‹œ:** `types.GenerateContentConfig(temperature=0.7, max_output_tokens=100)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GenerateContentConfig ì‚¬ìš©\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=0.3,  # ë‚®ì€ ì˜¨ë„ = ë” ê²°ì •ì ì¸ ì‘ë‹µ\n",
    "    max_output_tokens=50,\n",
    "    system_instruction=\"ë‹¹ì‹ ì€ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ëŠ” AIì…ë‹ˆë‹¤. í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Pythonì´ë€?\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ ê°„ê²°í•œ ì‘ë‹µ:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling ê´€ë ¨ íƒ€ì… ë¯¸ë¦¬ë³´ê¸°\n",
    "\n",
    "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ìì„¸íˆ ë‹¤ë£¨ì§€ë§Œ, í•µì‹¬ íƒ€ì…ì„ ë¯¸ë¦¬ ì‚´í´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "| íƒ€ì… | ì—­í•  |\n",
    "|-----|------|\n",
    "| `types.Tool` | í•¨ìˆ˜ ì„ ì–¸ë“¤ì„ ë¬¶ëŠ” ì»¨í…Œì´ë„ˆ |\n",
    "| `types.FunctionDeclaration` | ê°œë³„ í•¨ìˆ˜ì˜ ìŠ¤í‚¤ë§ˆ ì •ì˜ |\n",
    "| `types.FunctionCall` | ëª¨ë¸ì´ í˜¸ì¶œí•˜ë ¤ëŠ” í•¨ìˆ˜ ì •ë³´ |\n",
    "| `types.FunctionResponse` | í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Calling íƒ€ì… ë¯¸ë¦¬ë³´ê¸° (ì‹¤í–‰ì€ ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ)\n",
    "print(\"ğŸ”§ Function Calling ê´€ë ¨ íƒ€ì…ë“¤:\")\n",
    "print(f\"  - types.Tool: {types.Tool}\")\n",
    "print(f\"  - types.FunctionDeclaration: {types.FunctionDeclaration}\")\n",
    "print(f\"  - types.ToolConfig: {types.ToolConfig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ì‘ë‹µ ê°ì²´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ìš© ì‘ë‹µ ìƒì„±\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"1+1ì€?\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š ì‘ë‹µ ê°ì²´ ì „ì²´ êµ¬ì¡°:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `response.candidates` - ì‘ë‹µ í›„ë³´ë“¤\n",
    "\n",
    "ëª¨ë¸ì´ ìƒì„±í•œ ì‘ë‹µ í›„ë³´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë³´í†µ 1ê°œì´ì§€ë§Œ, ì„¤ì •ì— ë”°ë¼ ì—¬ëŸ¬ ê°œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**êµ¬ì¡°:**\n",
    "- `candidates[0].content` â†’ Content ê°ì²´\n",
    "- `candidates[0].content.parts[0].text` â†’ ì‹¤ì œ í…ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates êµ¬ì¡° íƒìƒ‰\n",
    "candidate = response.candidates[0]\n",
    "\n",
    "print(\"ğŸ“¦ candidate êµ¬ì¡°:\")\n",
    "print(f\"  - content.role: {candidate.content.role}\")\n",
    "print(f\"  - content.parts: {candidate.content.parts}\")\n",
    "print(f\"  - finish_reason: {candidate.finish_reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `response.usage_metadata` - í† í° ì‚¬ìš©ëŸ‰\n",
    "\n",
    "API í˜¸ì¶œì— ì‚¬ìš©ëœ í† í° ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ë¹„ìš© ê³„ì‚°ê³¼ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì— ì¤‘ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(human): response.usage_metadataì—ì„œ í† í° ì •ë³´ ì¶œë ¥\n",
    "# ëª©ì : í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ ë°©ë²• í•™ìŠµ\n",
    "# íŒíŠ¸: prompt_token_count, candidates_token_count, total_token_count ì†ì„±\n",
    "# ì˜ˆìƒ ì¶œë ¥:\n",
    "#   - ì…ë ¥ í† í°: Nê°œ\n",
    "#   - ì¶œë ¥ í† í°: Nê°œ\n",
    "#   - ì´ í† í°: Nê°œ\n",
    "\n",
    "usage = response.usage_metadata\n",
    "# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ì‹¤ìŠµ: Content ê°ì²´ë¡œ ë©€í‹°í„´ ëŒ€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©€í‹°í„´ ëŒ€í™” ì˜ˆì‹œ (ì œê³µë¨)\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=\"ë‚´ ì´ë¦„ì€ ì¤€ì˜ì´ì•¼\")]\n",
    "    )\n",
    "]\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì‘ë‹µ\n",
    "response1 = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=contents\n",
    ")\n",
    "print(f\"ğŸ¤– ì‘ë‹µ 1: {response1.text}\")\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€\n",
    "contents.append(response1.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(human): ë‘ ë²ˆì§¸ ì§ˆë¬¸ ì¶”ê°€í•˜ê³  ì‘ë‹µ ë°›ê¸°\n",
    "# ëª©ì : ë©€í‹°í„´ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ í™•ì¸\n",
    "# íŒíŠ¸: contents ë¦¬ìŠ¤íŠ¸ì— ìƒˆ Content ì¶”ê°€ í›„ generate_content í˜¸ì¶œ\n",
    "# ì˜ˆìƒ: ëª¨ë¸ì´ \"ì¤€ì˜\"ì´ë¼ëŠ” ì´ë¦„ì„ ê¸°ì–µí•˜ê³  ì‘ë‹µ\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì§ˆë¬¸: \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€?\"\n",
    "# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ì •ë¦¬\n",
    "\n",
    "### í•µì‹¬ ìš”ì•½\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ | ì—­í•  | ë¹„ìœ  |\n",
    "|----------|------|------|\n",
    "| `genai.Client` | API ì—°ê²° ê´€ë¦¬ | DB ì»¤ë„¥ì…˜ |\n",
    "| `types.Content` | ëŒ€í™” í„´ ì»¨í…Œì´ë„ˆ | ì±„íŒ… ë©”ì‹œì§€ |\n",
    "| `types.Part` | ì½˜í…ì¸  ì¡°ê° | ë©”ì‹œì§€ ë‚´ìš©ë¬¼ |\n",
    "| `types.GenerateContentConfig` | ìƒì„± ì„¤ì • | ëª¨ë¸ íŒŒë¼ë¯¸í„° |\n",
    "| `response.candidates` | ì‘ë‹µ í›„ë³´ | ìƒì„±ëœ ë‹µë³€ë“¤ |\n",
    "| `response.usage_metadata` | í† í° ì‚¬ìš©ëŸ‰ | ë¹„ìš© ì •ë³´ |\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "â†’ `02_gemini_ftn_calling_operate__basic.ipynb`ì—ì„œ Function Calling ì‹¤ìŠµ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kiwoom Study",
   "language": "python",
   "name": "kiwoom-study"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
